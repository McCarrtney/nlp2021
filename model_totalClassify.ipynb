{"metadata": {"language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}, "interpreter": {"hash": "dd511a26238e6ae0a0128ef6310b8218f6de319ae2077d3e90e8e15d9f9e182d"}}, "nbformat_minor": 5, "nbformat": 4, "cells": [{"cell_type": "code", "source": "import mindspore\nfrom mindspore import Tensor\nimport mindspore.ops as ops\nimport mindspore.nn as nn\nfrom mindspore.train.model import Model\nfrom mindspore.nn.metrics import Accuracy\nfrom mindspore.train.callback import LossMonitor, TimeMonitor\nimport mindspore.dataset as ds\nfrom mindspore import context\nfrom mindspore import dtype as mstype\n\nimport numpy as np\nimport h5py\nimport json\nimport re\nimport moxing as mox\nimport pickle", "metadata": {"trusted": true}, "execution_count": 1, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v1.17.3-d858ff4a\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "context.set_context(mode=context.GRAPH_MODE, device_target='Ascend', device_id=0)", "metadata": {"trusted": true}, "execution_count": 2, "outputs": []}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"s3://myobsbrower/nlp/nlp2021-1/annotations\", dst_url='./annotations')\nmox.file.copy_parallel(src_url=\"s3://myobsbrower/nlp/nlp2021-1/questions\", dst_url='./questions')\nmox.file.copy_parallel(src_url=\"s3://myobsbrower/nlp/nlp2021-1/vocab\", dst_url='./vocab')\nmox.file.copy_parallel(src_url=\"s3://myobsbrower/nlp/nlp2021-1/image_features\", dst_url='./image_features')\nmox.file.copy_parallel(src_url=\"s3://myobsbrower/nlp/nlp2021-1/dataset.pkl\", dst_url='./dataset.pkl')", "metadata": {"trusted": true}, "execution_count": 3, "outputs": []}, {"cell_type": "code", "source": "# class text_encoder(nn.Cell):\n#     def __init__(self, vocab_size, embedding_size=2048, max_len=100):\n#         super(text_encoder, self).__init__()\n\n#         self.vocab_size = vocab_size\n#         self.embedding_size = embedding_size\n#         self.max_len = max_len\n\n#         self.embed = nn.Embedding(vocab_size, embedding_size)\n#         self.WQ = nn.Dense(embedding_size, embedding_size)\n#         self.WK = nn.Dense(embedding_size, embedding_size)\n#         self.WV = nn.Dense(embedding_size, embedding_size)\n\n#         self.pe = self.pe_gen()\n        \n#         self.matmul = ops.BatchMatMul()\n#         self.transpose = ops.Transpose()\n#         self.softmax = nn.Softmax()\n#         self.reducemax = ops.ReduceMax(keep_dims=True)\n#         self.print = ops.Print()\n\n#     def pe_gen(self):\n#         pe = np.empty((self.max_len, self.embedding_size))\n#         even = 10000**(np.arange(self.embedding_size, step=2)/self.embedding_size)\n#         odd = 10000**(np.arange(self.embedding_size-1, step=2)/self.embedding_size)\n#         for pos in range(self.max_len):\n#             pe[pos, ::2] = np.sin(pos/even)\n#             pe[pos, 1::2] = np.cos(pos/odd)\n#         return Tensor(pe.astype('float32'))\n\n#     def construct(self, x, squeeze=False): # len\n#         x = self.embed(x) # batch * len * emb\n#         x = x + self.pe[:x.shape[1]] # batch * len * emb\n        \n#         Q = self.WQ(x) # batch * len * emb\n#         K = self.WK(x) # batch * len * emb\n#         V = self.WV(x) # batch * len * emb\n        \n#         QK = self.matmul(Q, self.transpose(K, (0,2,1))) # batch * len * len\n#         Z = self.matmul(self.softmax(QK), V) # batch * len * emb\n        \n#         if squeeze:\n#             Z = self.reducemax(Z, 1) # batch * 1 * emb\n#         return Z # batch * 1 * emb\nclass text_encoder(nn.Cell):\n    def __init__(self, vocab_size, embedding_size=500, max_len=100):\n        super(text_encoder, self).__init__()\n\n        self.vocab_size = vocab_size\n        self.embedding_size = embedding_size\n        self.max_len = max_len\n\n        self.embed = nn.Embedding(vocab_size, embedding_size)\n        self.lstm = nn.LSTM(embedding_size, 2048, 1, has_bias=True, batch_first=True, bidirectional=False)\n        self.h0 = Tensor(np.random.randn(1, 128, 2048).astype(np.float32))\n        self.c0 = Tensor(np.random.randn(1, 128, 2048).astype(np.float32))\n        self.transpose = ops.Transpose()\n\n    def construct(self, x, squeeze=False): # len\n        x = self.embed(x) # batch * len * emb\n        batch_size = x.shape[0]\n        \n        _, (hn, cn) = self.lstm(x, (self.h0[:,:batch_size,:], self.c0[:,:batch_size,:]))\n        hn = self.transpose(hn, (1,0,2))\n        \n        return hn\n\n# class text_encoder(nn.Cell):\n#     def __init__(self, vocab_size, embedding_size=2048, max_len=100):\n#         super(text_encoder, self).__init__()\n\n#         self.vocab_size = vocab_size\n#         self.embedding_size = embedding_size\n#         self.max_len = max_len\n\n#         self.embed = nn.Embedding(vocab_size, embedding_size)\n#         self.WQ = nn.Dense(embedding_size, embedding_size)\n#         self.WK = nn.Dense(embedding_size, embedding_size)\n#         self.WV = nn.Dense(embedding_size, embedding_size)\n\n#         self.pe = self.pe_gen()\n        \n#         self.matmul = ops.BatchMatMul()\n#         self.transpose = ops.Transpose()\n#         self.softmax = nn.Softmax()\n#         self.reducemax = ops.ReduceMean(keep_dims=True)\n#         self.layernorm = nn.LayerNorm((embedding_size,))\n#         self.lstm = nn.LSTM(embedding_size, embedding_size)\n#         self.print = ops.Print()\n    \n#     def pe_gen(self):\n#         pe = np.empty((self.max_len, self.embedding_size))\n#         even = 10000**(np.arange(self.embedding_size, step=2)/self.embedding_size)\n#         odd = 10000**(np.arange(self.embedding_size-1, step=2)/self.embedding_size)\n#         for pos in range(self.max_len):\n#             pe[pos, ::2] = np.sin(pos/even)\n#             pe[pos, 1::2] = np.cos(pos/odd)\n#         return Tensor(pe.astype('float32'))\n    \n#     def construct(self, x, squeeze=False): # len\n#         x = self.embed(x) # batch * len * emb\n#         batch_size = x.shape[0]\n#         h = Tensor(np.zeros([1, batch_size, self.embedding_size]).astype(np.float32))\n#         c = Tensor(np.zeros([1, batch_size, self.embedding_size]).astype(np.float32))\n#         Z = x\n#         if squeeze:\n#             _, (Z, __) = self.lstm(self.transpose(Z, (1,0,2)), (self.h[:, :x.shape[0]], self.c[:, :x.shape[0]])) # 1 * batch * emb\n#             Z = self.transpose(Z, (1,0,2)) # batch * 1 * emb\n#             # Z = self.reducemax(Z, 1) # batch * 1 * emb\n#         return Z # batch * 1 * emb", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "code", "source": "class block(nn.Cell):\n    def __init__(self, input_size=2048, hidden_size=512):\n        super(block, self).__init__()\n        self.Wq = nn.Dense(input_size, hidden_size)\n        self.Wi = nn.Dense(input_size, hidden_size, has_bias=False)\n        self.Wp = nn.Dense(hidden_size, 1)\n        self.transpose = ops.Transpose()\n        self.tanh = nn.Tanh()\n        self.softmax = nn.Softmax(0)\n        self.reduce_sum = ops.ReduceSum()\n        self.matmul = ops.BatchMatMul()\n        self.dropout = nn.Dropout()\n    \n    def construct(self, v_i, v_q):\n        encoded_q = self.Wq(v_q) # batch * 1 * hid\n        encoded_i = self.Wi(self.transpose(v_i, (0,2,1))) # batch * 36 * hid\n        hA = self.tanh(encoded_q + encoded_i) # batch * 36 * hid\n        hA = self.dropout(hA)\n        pI = self.softmax(self.Wp(hA)) # batch * 36 * 1\n        #vI = self.matmul(self.transpose(pI, (0,2,1)), hA) # batch * 1 * hid\n        vI = self.matmul(self.transpose(pI, (0,2,1)), self.transpose(v_i, (0,2,1)))\n        u = vI + v_q\n        return u\n\nclass SAN(nn.Cell):\n    def __init__(self, hidden_size=2048):\n        super(SAN, self).__init__()\n        \n        self.block0 = block(hidden_size, 512)\n        self.block1 = block(hidden_size, 512)\n        #self.block2 = block(hidden_size)\n        #self.block3 = block(hidden_size)\n\n    def construct(self, v_i, v_q): # v_i: batch * 36 * hid, v_q: batch * 1 * hid\n        u0 = self.block0(v_i, v_q)\n        u1 = self.block1(v_i, u0)\n        #u2 = self.block2(v_i, u1)\n        #u3 = self.block3(v_i, u2)\n\n        return u1 # 1 * hid", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "code", "source": "class VQA(nn.Cell):\n    def __init__(self, question_vocab_size, answer_vocab_size, nb_answers, hidden_size=2048):\n        super(VQA, self).__init__()\n        self.question_encoder = text_encoder(question_vocab_size, 500)\n        self.answer_encoder = text_encoder(answer_vocab_size, 500)\n        self.SAN = SAN(hidden_size)\n        self.classifier = nn.Dense(hidden_size, nb_answers)\n        \n        self.matmul = ops.BatchMatMul()\n        self.transpose = ops.Transpose()\n        self.argmax = ops.Argmax()\n        self.softmax = nn.Softmax()\n        self.cast = ops.Cast()\n        self.print = ops.Print()\n        self.dropout = nn.Dropout()\n\n    def construct(self, x):\n        v_i = x[:, :-1]\n        q = self.cast(x[:, -2:-1, :], mindspore.int32).view(x.shape[0],-1) # batch * 1 * 36\n        v_q = self.question_encoder(q, True) # batch * 1 * hid\n        uk = self.SAN(v_i, v_q) # batch * 1 * hid\n        score = self.classifier(uk) # batch * 1 * n\n        score = self.dropout(score)\n        prob = self.softmax(score) # batch * 1 * n\n        chosen = self.argmax(score)\n        \n        return score.view(x.shape[0], -1)\n        # return score\n        # return prob.view(x.shape[0], -1)\n        # return prob\n        # return chosen", "metadata": {"trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "code", "source": "categories = ['train', 'val', 'test']", "metadata": {"trusted": true}, "execution_count": 7, "outputs": []}, {"cell_type": "code", "source": "questions = {}\nannotations = {}\nfeatures = {}\n\nfor c in categories:\n    quest_json = open('./questions/{}.json'.format(c))\n    quest = json.load(quest_json)\n    quest_json.close()\n    questions[c] = quest['questions']\n\n    anno_json = open('./annotations/{}.json'.format(c))\n    anno = json.load(anno_json)\n    anno_json.close()\n    annotations[c] = anno['annotations']\n\n    try:\n        features[c] = h5py.File('./image_features/image-{}.h5'.format(c), 'r')\n    except:\n        pass\n\nvocab_file = open('./vocab/test.json')\nvocab = json.load(vocab_file)\nvocab_file.close()", "metadata": {"trusted": true}, "execution_count": 8, "outputs": []}, {"cell_type": "code", "source": "_special_chars = re.compile('[^a-z0-9 ]*')\n_period_strip = re.compile(r'(?!<=\\d)(\\.)(?!\\d)')\n_comma_strip = re.compile(r'(\\d)(,)(\\d)')\n_punctuation_chars = re.escape(r';/[]\"{}()=+\\_-><@`,?!')\n_punctuation = re.compile(r'([{}])'.format(re.escape(_punctuation_chars)))\n_punctuation_with_a_space = re.compile(r'(?<= )([{0}])|([{0}])(?= )'.format(_punctuation_chars))\n\ndef question_tokenize(question):\n    question = question.lower()[:-1]\n    question = _special_chars.sub('', question)\n    return question.split(' ')\n\ndef answer_tokenize(answer):\n    if _punctuation.search(answer) is None:\n        return answer\n    answer = _punctuation_with_a_space.sub('', answer)\n    if re.search(_comma_strip, answer) is not None:\n        answer = answer.replace(',', '')\n    answer = _punctuation.sub(' ', answer)\n    answer = _period_strip.sub('', answer)\n    return answer.strip()\n\ndef question2vec(question):\n    return Tensor([vocab['question'][word] for word in question_tokenize(question)])\n\ndef answer2vec(answer):\n    return Tensor([vocab['answer'][answer_tokenize(answer)]])", "metadata": {"trusted": true}, "execution_count": 9, "outputs": []}, {"cell_type": "code", "source": "data_file = open('dataset.pkl', 'rb')\ndataset = pickle.load(data_file)\ndata_file.close()", "metadata": {"trusted": true}, "execution_count": 10, "outputs": []}, {"cell_type": "code", "source": "nb_answers = max([max([data['answer_label'] for data in dataset[c]]) for c in categories]) + 1", "metadata": {"trusted": true}, "execution_count": 11, "outputs": []}, {"cell_type": "code", "source": "nb_choices = 16\nnb_epoches = 10", "metadata": {"trusted": true}, "execution_count": 12, "outputs": []}, {"cell_type": "code", "source": "vqa = VQA(len(vocab['question']), len(vocab['answer']), nb_answers)", "metadata": {"trusted": true}, "execution_count": 13, "outputs": []}, {"cell_type": "code", "source": "id2idx = {'train' : {}, 'test' : {}, 'val' : {}}\nfor c in categories:\n    id2idx[c] = {id : i for i, id in enumerate(features[c]['ids'])}", "metadata": {"trusted": true}, "execution_count": 14, "outputs": []}, {"cell_type": "code", "source": "id2idx_file = open('id2idx.pkl', 'wb')\npickle.dump(id2idx, id2idx_file)\nid2idx_file.close()\nmox.file.copy_parallel(src_url=\"./id2idx.pkl\", dst_url='s3://myobsbrower/nlp/nlp2021-1/id2idx.pkl')", "metadata": {"trusted": true}, "execution_count": 15, "outputs": []}, {"cell_type": "code", "source": "stop_index = 8717", "metadata": {"trusted": true}, "execution_count": 16, "outputs": []}, {"cell_type": "code", "source": "input_data = {'train' : [], 'test' : [], 'val' : []}\nfor c in categories:\n    for i, data in enumerate(dataset[c]):\n        if i >= 10000:\n            break\n        question = np.ones((36,), 'int32') * stop_index\n        question_vec = data['question'].astype('int32')\n        question[:question_vec.shape[0]] = question_vec\n        image_text = np.concatenate((features[c]['features'][id2idx[c][data['image_id']]].astype('float32'), \n                                    question.astype('float32').reshape(1,-1)), 0)\n        input_data[c].append(\n            (image_text, np.array([data['answer_label']], 'int32')[0])\n        )", "metadata": {"trusted": true}, "execution_count": 17, "outputs": []}, {"cell_type": "code", "source": "class Generator():\n    def __init__(self, input_list):\n        self.input_list=input_list\n    def __getitem__(self,item):\n        return (self.input_list[item][0], self.input_list[item][1])\n    def __len__(self):\n        return len(self.input_list)", "metadata": {"trusted": true}, "execution_count": 18, "outputs": []}, {"cell_type": "code", "source": "input_ds = {}\nfor c in categories:\n    input_ds[c] = ds.GeneratorDataset(\n        source=Generator(input_list=input_data[c]), \n        column_names=[\"data\", \"label\"],\n        shuffle=False\n    )\n    input_ds[c] = input_ds[c].batch(batch_size=64)\n    # if c == 'train':\n        # input_ds[c] = input_ds[c].repeat(nb_epoches)", "metadata": {"trusted": true}, "execution_count": 19, "outputs": []}, {"cell_type": "code", "source": "opt = nn.Adam(vqa.get_parameters(), learning_rate=0.001, weight_decay=3e-5)\n# opt = nn.Momentum(vqa.get_parameters(), 0.001, 0.9)\nloss = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\nmodel = Model(vqa, loss_fn=loss, optimizer=opt, metrics={'acc': Accuracy()})", "metadata": {"trusted": true}, "execution_count": 20, "outputs": []}, {"cell_type": "code", "source": "time_cb = TimeMonitor(data_size=64)\nloss_cb = LossMonitor()", "metadata": {"trusted": true}, "execution_count": 21, "outputs": []}, {"cell_type": "code", "source": "model.train(20, input_ds['train'], callbacks=[time_cb, loss_cb])\nprint('train_success')", "metadata": {"trusted": true}, "execution_count": null, "outputs": [{"name": "stdout", "text": "epoch: 1 step: 157, loss is 7.4612937\nepoch time: 109855.398 ms, per step time: 699.716 ms\nepoch: 2 step: 157, loss is 5.8511934\nepoch time: 70623.371 ms, per step time: 449.830 ms\nepoch: 3 step: 157, loss is 5.642644\nepoch time: 70627.251 ms, per step time: 449.855 ms\nepoch: 4 step: 157, loss is 5.104364\nepoch time: 70624.819 ms, per step time: 449.840 ms\nepoch: 5 step: 157, loss is 6.354743\nepoch time: 70627.364 ms, per step time: 449.856 ms\nepoch: 6 step: 157, loss is 4.7461033\nepoch time: 70629.914 ms, per step time: 449.872 ms\nepoch: 7 step: 157, loss is 4.9699254\nepoch time: 70629.806 ms, per step time: 449.871 ms\nepoch: 8 step: 157, loss is 5.4195204\nepoch time: 70626.843 ms, per step time: 449.853 ms\nepoch: 9 step: 157, loss is 3.763872\nepoch time: 70646.902 ms, per step time: 449.980 ms\nepoch: 10 step: 157, loss is 4.8594546\nepoch time: 70638.940 ms, per step time: 449.930 ms\nepoch: 11 step: 157, loss is 4.642271\nepoch time: 70628.031 ms, per step time: 449.860 ms\nepoch: 12 step: 157, loss is 5.2656302\nepoch time: 70630.763 ms, per step time: 449.877 ms\nepoch: 13 step: 157, loss is 4.7709403\nepoch time: 70622.441 ms, per step time: 449.824 ms\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "acc = model.eval(input_ds['test'])\nprint(\"accuracy: \", acc)", "metadata": {"trusted": true}, "execution_count": 23, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.12470143312101911}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "from mindspore.train.callback import ModelCheckpoint\nckpt_cb = ModelCheckpoint()\nmodel.train(1, input_ds['train'], callbacks=[time_cb, loss_cb, ckpt_cb],dataset_sink_mode=False)\nprint('train_success')", "metadata": {}, "execution_count": 22, "outputs": [{"name": "stdout", "text": "epoch: 1 step: 1, loss is 8.672701\nepoch time: 51597.254 ms, per step time: 51597.254 ms\ntrain_success\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy(src_url=\"./CKP-1_694.ckpt\", dst_url='s3://myobsbrower/nlp/nlp2021-1/CKP-1_694.ckpt')", "metadata": {}, "execution_count": 24, "outputs": []}, {"cell_type": "code", "source": "acc = model.eval(input_ds['test'], dataset_sink_mode=False)\nprint(\"accuracy: \", acc)", "metadata": {}, "execution_count": 23, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.1875}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "model.train(1, input_ds['train'], callbacks=[time_cb, loss_cb, ckpt_cb], dataset_sink_mode=False)\nprint('the second train succeeds')", "metadata": {}, "execution_count": 24, "outputs": [{"name": "stdout", "text": "epoch: 1 step: 1, loss is 6.4220457\nepoch time: 2738.978 ms, per step time: 2738.978 ms\nthe second train succeeds\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "acc = model.eval(input_ds['test'], dataset_sink_mode=False)\nprint(\"accuracy: \", acc)", "metadata": {}, "execution_count": 25, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.1875}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "!ls", "metadata": {}, "execution_count": 26, "outputs": [{"name": "stdout", "text": "annotations   CKP-graph.meta  id2idx.pkl      kernel_meta  somas_meta\nCKP-1_1.ckpt  dataset.pkl     image_features  questions    vocab\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "from mindspore import load_checkpoint, load_param_into_net\n\nparam_dict = load_checkpoint(\"CKP-1_1.ckpt\")\nload_param_into_net(vqa, param_dict)\n\nacc = model.eval(input_ds['test'], dataset_sink_mode=False)", "metadata": {}, "execution_count": 27, "outputs": []}, {"cell_type": "code", "source": "print(\"accuracy: \", acc)", "metadata": {}, "execution_count": 28, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.1875}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "from mindspore import load_checkpoint, load_param_into_net\n\nparam_dict = load_checkpoint(\"CKP-1_1.ckpt\")\nload_param_into_net(vqa, param_dict)\n\nacc = model.eval(input_ds['test'], dataset_sink_mode=False)\nprint(\"accuracy: \", acc)", "metadata": {}, "execution_count": 29, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.1875}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "model.train(1, input_ds['train'], callbacks=[time_cb, loss_cb, ckpt_cb], dataset_sink_mode=False)\nprint('the third train succeeds')", "metadata": {}, "execution_count": 30, "outputs": [{"name": "stdout", "text": "epoch: 1 step: 1, loss is 6.4220457\nepoch time: 2736.719 ms, per step time: 2736.719 ms\nthe third train succeeds\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "mox.file.copy(src_url=\"s3://myobsbrower/nlp/nlp2021-1/CKP-1_694.ckpt\", dst_url='./CKP-1_694.ckpt')", "metadata": {}, "execution_count": 25, "outputs": []}, {"cell_type": "code", "source": "from mindspore import load_checkpoint, load_param_into_net\n\nvqa1 = VQA(len(vocab['question']), len(vocab['answer']), nb_answers)\nparam_dict = load_checkpoint(\"CKP-1_694.ckpt\")\nload_param_into_net(vqa1, param_dict)\n\nopt1 = nn.Adam(vqa1.get_parameters(), learning_rate=0.0001)\nloss1 = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\nmodel1 = Model(vqa1, loss_fn=loss1, optimizer=opt1, metrics={'acc': Accuracy()})\n\nacc = model1.eval(input_ds['test'], dataset_sink_mode=False)\nprint(\"accuracy: \", acc)", "metadata": {}, "execution_count": 33, "outputs": [{"name": "stdout", "text": "accuracy:  {'acc': 0.148}\n", "output_type": "stream"}]}, {"cell_type": "code", "source": "", "metadata": {}, "execution_count": null, "outputs": []}]}